{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gQhIyRIHNIhu"
   },
   "source": [
    "#**Assessment Task 3 (40 marks)**\n",
    "\n",
    "##Submission Instruction\n",
    "1.  Student should insert Python code or text responses into the cell followed by the question.\n",
    "\n",
    "2.  For answers regarding discussion or explanation, **maximum five sentences are suggested**.\n",
    "\n",
    "3.  Rename this notebook file appending your student ID. For example, for student ID 1234, the submitted file name should be A3_1234.ipynb.\n",
    "\n",
    "4.  Insert your student ID and name in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gdZPzuPLNM5f"
   },
   "outputs": [],
   "source": [
    "# Student ID: 219446914\n",
    "\n",
    "# Student name: Bui, Nhu Hoang Ha (Chloe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8Bb-CS27NWdS"
   },
   "source": [
    "## Background\n",
    "\n",
    "Environment and its changes are the most complex system. It is unarguably accepted that the temperature changes are greately affected by various environmental factors. Many of them are positively related to the  change, whereas, some have negative correlation. In this assesment task, you will analyse relationship among various environmental factors, which affect temperature.\n",
    "\n",
    "##The dataset\n",
    "\n",
    "**Dataset file name:** weather_dataset.csv\n",
    "\n",
    "**Dataset description:** The dataset contains total 10 features. Each row contains an hourly record of weather status and the data was recorded for the time period between 2006 and 2016.\n",
    "\n",
    "**Features and labels:** \n",
    "\n",
    "1.   recording_date_time (date_time): Date and time the data was recorded\n",
    "2.   precip_type (string): Precipitation status, blank (no value) indicates unknown status\n",
    "3.   temperature (float): Temperature in degree Celsius\n",
    "4.   apparent_temperature (float): Feel like temperature in degree Celsius\n",
    "5.   humidity (float): Percentage amount of water vapour in the air \n",
    "6.   wind_speed (float): Speed of the wind in km per hour\n",
    "7.   wind_bearing (int): The direction of wind in degree in geo-polar co-ordinate. Value 0 means perfect east, 90 means perfect north, 180 and 270 means west and south respectively.\n",
    "8.   visibility (float): Distance in km that is visible in naked eyes.\n",
    "9.   cloud_cover (float): The fraction of the sky obscured by clouds. The value is 1 if the observed area is fully cloudy, 0 if no clouds and other fractional value indicates the portion of the area covered by clouds.\n",
    "10.   pressure (float): Air pressure or atmospheric in milibars\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TkUeSXbIODoE"
   },
   "source": [
    "##**Part 1: Linear Regression:**  **(25 marks)**\n",
    "\n",
    "\n",
    "1.   Load the dataset and split the data for training and testing - consider the data of last 2 years (2015 and 2016) for testing. Now exclude recording_date_time column from both training and test sets. Display the shape of training and test sets. **(3 marks)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KugpF4o5OKHD"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df=pd.read_csv('weather_dataset.csv')\n",
    "\n",
    "# Assuming feature=temperature as target variable\n",
    "X=df.iloc[78908: ,[1,3,4,5,6,7,8,9] ].values\n",
    "y=df.iloc[78908: ,[2]].values\n",
    "\n",
    "#Converting String object of Pericipation type to float\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# le=LabelEncoder()\n",
    "# ohe=OneHotEncoder(categorical_features=[0])\n",
    "# X[:,0]=le.fit_transform(X[:,0])\n",
    "# X=ohe.fit_transform(X).toarray()\n",
    "\n",
    "ct = ColumnTransformer([(\"precip_type\", OneHotEncoder(), [0])], remainder = 'passthrough')\n",
    "X = ct.fit_transform(X)\n",
    "\n",
    "X=pd.DataFrame(data=X)\n",
    "y=pd.DataFrame(data=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape-> (13158, 9)\n",
      "X_test.shape-> (4387, 9)\n",
      "y_train.shape-> (13158, 1)\n",
      "y_test.shape-> (4387, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 1)\n",
    "\n",
    "print(\"X_train.shape->\",X_train.shape)\n",
    "print(\"X_test.shape->\",X_test.shape)\n",
    "print(\"y_train.shape->\",y_train.shape)\n",
    "print(\"y_test.shape->\",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recording_date_time</th>\n",
       "      <th>precip_type</th>\n",
       "      <th>temperature</th>\n",
       "      <th>apparent_temperature</th>\n",
       "      <th>humidity</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>wind_bearing</th>\n",
       "      <th>visibility</th>\n",
       "      <th>cloud_cover</th>\n",
       "      <th>pressure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2006-04-01 00:00:00.000 +0200</td>\n",
       "      <td>rain</td>\n",
       "      <td>9.47</td>\n",
       "      <td>7.39</td>\n",
       "      <td>0.89</td>\n",
       "      <td>14.12</td>\n",
       "      <td>251</td>\n",
       "      <td>15.83</td>\n",
       "      <td>0</td>\n",
       "      <td>1015.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006-04-01 01:00:00.000 +0200</td>\n",
       "      <td>rain</td>\n",
       "      <td>9.36</td>\n",
       "      <td>7.23</td>\n",
       "      <td>0.86</td>\n",
       "      <td>14.26</td>\n",
       "      <td>259</td>\n",
       "      <td>15.83</td>\n",
       "      <td>0</td>\n",
       "      <td>1015.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2006-04-01 02:00:00.000 +0200</td>\n",
       "      <td>rain</td>\n",
       "      <td>9.38</td>\n",
       "      <td>9.38</td>\n",
       "      <td>0.89</td>\n",
       "      <td>3.93</td>\n",
       "      <td>204</td>\n",
       "      <td>14.96</td>\n",
       "      <td>0</td>\n",
       "      <td>1015.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2006-04-01 03:00:00.000 +0200</td>\n",
       "      <td>rain</td>\n",
       "      <td>8.29</td>\n",
       "      <td>5.94</td>\n",
       "      <td>0.83</td>\n",
       "      <td>14.10</td>\n",
       "      <td>269</td>\n",
       "      <td>15.83</td>\n",
       "      <td>0</td>\n",
       "      <td>1016.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2006-04-01 04:00:00.000 +0200</td>\n",
       "      <td>rain</td>\n",
       "      <td>8.76</td>\n",
       "      <td>6.98</td>\n",
       "      <td>0.83</td>\n",
       "      <td>11.04</td>\n",
       "      <td>259</td>\n",
       "      <td>15.83</td>\n",
       "      <td>0</td>\n",
       "      <td>1016.51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             recording_date_time precip_type  temperature  \\\n",
       "0  2006-04-01 00:00:00.000 +0200        rain         9.47   \n",
       "1  2006-04-01 01:00:00.000 +0200        rain         9.36   \n",
       "2  2006-04-01 02:00:00.000 +0200        rain         9.38   \n",
       "3  2006-04-01 03:00:00.000 +0200        rain         8.29   \n",
       "4  2006-04-01 04:00:00.000 +0200        rain         8.76   \n",
       "\n",
       "   apparent_temperature  humidity  wind_speed  wind_bearing  visibility  \\\n",
       "0                  7.39      0.89       14.12           251       15.83   \n",
       "1                  7.23      0.86       14.26           259       15.83   \n",
       "2                  9.38      0.89        3.93           204       14.96   \n",
       "3                  5.94      0.83       14.10           269       15.83   \n",
       "4                  6.98      0.83       11.04           259       15.83   \n",
       "\n",
       "   cloud_cover  pressure  \n",
       "0            0   1015.13  \n",
       "1            0   1015.63  \n",
       "2            0   1015.94  \n",
       "3            0   1016.41  \n",
       "4            0   1016.51  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tir1JyxlOVQf"
   },
   "source": [
    "2.  Consider the 'temperature' as the target. List the insignificant features for predicting temperature, if any. Explain your findings. **(5 marks)**\n",
    "<br/><font color='green'>**[Hint for students: See the \"7.3 Relevance and Covariance among features or variables\" for more information.]** <font/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hMLc-93uOMhY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Attributes       Score\n",
      "0           0   19.762424\n",
      "1           1   19.762424\n",
      "2           2  589.678495\n",
      "3           3    6.259292\n",
      "4           4    1.058334\n",
      "5           5    1.021604\n",
      "6           6    3.028996\n",
      "7           7         NaN\n",
      "8           8    1.836459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hoangha/opt/anaconda3/lib/python3.7/site-packages/sklearn/feature_selection/_univariate_selection.py:114: UserWarning: Features [7] are constant.\n",
      "  UserWarning)\n",
      "/Users/hoangha/opt/anaconda3/lib/python3.7/site-packages/sklearn/feature_selection/_univariate_selection.py:115: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest,chi2,f_classif\n",
    "significant_features=SelectKBest(score_func=f_classif,k=4)\n",
    "fit=significant_features.fit(X,y.values.ravel())\n",
    "dfscores=pd.DataFrame(fit.scores_)\n",
    "dfcolumns=pd.DataFrame(X.columns)\n",
    "featureScores=pd.concat([dfcolumns,dfscores],axis=1)\n",
    "featureScores.columns=['Attributes','Score']\n",
    "print(featureScores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Higher the value of scores higher will be the dependecy of target variable with that attribute like the score of Apparent temperature with temperature is 589.678, score of pericipation type is  19.762, for humidity score is 6.259, for visibility score is 3.029 and for pressure score is 1.836. Therefore, for predicting temperature, these features are important and score of cloud_cover is 0 hence we can count it as an insignificant feature. We also have features with scores of almost 1 (wind_speed and wind_bearing) and those can also be considered as insignificant as compared to the ones mentioned above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_mC_pm60V4VB"
   },
   "source": [
    "3.  Now create a linear model considering the 'temperature' as the target variable and other columns as features (you can optionally remove non-contributing features). Show the test performance (as Mean Absolute Error, MAE) of the model. **(5 marks)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wUIhRhssWq8h"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE on training Set= 0.7055018301455152\n",
      "MAE on testing Set= 0.7115532357898692\n"
     ]
    }
   ],
   "source": [
    "# Considering all the features\n",
    "from sklearn.linear_model import LinearRegression\n",
    "linear_model = LinearRegression()\n",
    "linear_model.fit(X_train, y_train)\n",
    "train_predict=linear_model.predict(X_train)\n",
    "test_predict=linear_model.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "print('MAE on training Set=',mean_absolute_error(y_train,train_predict))\n",
    "print('MAE on testing Set=',mean_absolute_error(y_test,test_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE on training Set= 0.7517108496423581\n",
      "MAE on testing Set= 0.7488063267219829\n"
     ]
    }
   ],
   "source": [
    "# Considering only significant attributes\n",
    "X_significant=X.iloc[:,[0,1,2,3,6,8]].values\n",
    "X_significant=pd.DataFrame(data=X_significant)\n",
    "\n",
    "X_sig_train, X_sig_test, y_sig_train, y_sig_test = train_test_split(X_significant, y, test_size = 0.25, random_state = 1)\n",
    "linear_model.fit(X_sig_train, y_sig_train)\n",
    "train_sig_predict=linear_model.predict(X_sig_train)\n",
    "test_sig_predict=linear_model.predict(X_sig_test)\n",
    "\n",
    "print('MAE on training Set=',mean_absolute_error(y_sig_train,train_sig_predict))\n",
    "print('MAE on testing Set=',mean_absolute_error(y_sig_test,test_sig_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MAE of both training and testing set when considering all the features are slightly lower than the MAE of training and testing set when removing non-contributing attributes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v428CdiaOaad"
   },
   "source": [
    "4.   Find the feature which shows maximum correlation with \"pressure\". Create a linear regression model to predict temperature using these two features ('pressure' and the one which shows maximum correlation). Compare the performance of this simplified model with the model developed in the previous question (Q-3). Explain the performance variation, if any. **(6 marks)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aKsPiuGCOM5F"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1440 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "def plot_corr(df, size=20):\n",
    "    corr = df.corr()    # data frame correlation function\n",
    "    fig, ax = plt.subplots(figsize=(size, size))# The subplots command in the background will call plt.figure(), and any keywords will be passed along\n",
    "    ax.matshow(corr)   # heatmap with matshow, color code the rectangles by correlation value\n",
    "    plt.xticks(range(len(corr.columns)), corr.columns)  # draw x tick marks\n",
    "    plt.yticks(range(len(corr.columns)), corr.columns)  # draw y tick marks\n",
    "    \n",
    "plot_corr(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      temperature  apparent_temperature  humidity  wind_speed  \\\n",
      "temperature              1.000000              0.992628 -0.632253    0.008957   \n",
      "apparent_temperature     0.992628              1.000000 -0.602570   -0.056649   \n",
      "humidity                -0.632253             -0.602570  1.000000   -0.224951   \n",
      "wind_speed               0.008957             -0.056649 -0.224951    1.000000   \n",
      "wind_bearing             0.029988              0.029030  0.000735    0.103823   \n",
      "visibility               0.392781              0.381658 -0.369077    0.100745   \n",
      "cloud_cover                   NaN                   NaN       NaN         NaN   \n",
      "pressure                -0.005447             -0.000218  0.005454   -0.049260   \n",
      "\n",
      "                      wind_bearing  visibility  cloud_cover  pressure  \n",
      "temperature               0.029988    0.392781          NaN -0.005447  \n",
      "apparent_temperature      0.029030    0.381658          NaN -0.000218  \n",
      "humidity                  0.000735   -0.369077          NaN  0.005454  \n",
      "wind_speed                0.103823    0.100745          NaN -0.049260  \n",
      "wind_bearing              1.000000    0.047614          NaN -0.011651  \n",
      "visibility                0.047614    1.000000          NaN  0.059826  \n",
      "cloud_cover                    NaN         NaN          NaN       NaN  \n",
      "pressure                 -0.011651    0.059826          NaN  1.000000  \n"
     ]
    }
   ],
   "source": [
    "correlation=df.corr()\n",
    "print(correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE on training Set= 6.438456913499031\n",
      "MAE on testing Set= 6.485806963165343\n"
     ]
    }
   ],
   "source": [
    "# Above correlation dataframe suggests that pressure shows maximum correlation with visibility.\n",
    "# Now predicting temperature using two features pressure and visibility\n",
    "\n",
    "X_new=X.iloc[:,[6,8]].values\n",
    "X_new=pd.DataFrame(data=X_new)\n",
    "\n",
    "X_new_train, X_new_test, y_new_train, y_new_test = train_test_split(X_new, y, test_size = 0.3, random_state = 1)\n",
    "linear_model.fit(X_new_train, y_new_train)\n",
    "train_new_predict=linear_model.predict(X_new_train)\n",
    "test_new_predict=linear_model.predict(X_new_test)\n",
    "\n",
    "print('MAE on training Set=',mean_absolute_error(y_new_train,train_new_predict))\n",
    "print('MAE on testing Set=',mean_absolute_error(y_new_test,test_new_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clear performance variation can be observed through mean absolute error (MAE) score between the current model and one build in question 3. MAE in this model comes out to be 6.438456913499031 for trainning set and 6.485806963165343 for testing set whereas it was 0.7517108496423581 and 0.7488063267219829 for training and testing set, respectively in question 3. This is because model developed in question 3 was based on features which were significant to predict our target variable whereas in this question we build our model based on feature that has maximum correlation with pressure which is not our target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0-jv9d7oOtHe"
   },
   "source": [
    "5. Apportion the complete dataset into training and test sets, with an 40-60 split. **(6 marks)**\n",
    "\n",
    "  (a)  Train a linear regression model without considering overfitting scenario and report the test performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jNk_egyXONc2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING Score= 0.9901267080741581\n",
      "TESTING Score= 0.9901407708553324\n",
      "MAE on training Set= 0.7412921283059758\n",
      "MAE on testing Set= 0.740313432064378\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import datetime as dt\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "df['Date'] = pd.to_datetime(df['recording_date_time'],utc=True)\n",
    "df['year'] = df['Date'].dt.year\n",
    "df['month'] = df['Date'].dt.month\n",
    "df['day'] = df['Date'].dt.day\n",
    "df['hour'] = df['Date'].dt.hour\n",
    "\n",
    "X1=df.iloc[:,[1,3,4,5,6,7,8,9,11,12,13,14]].values\n",
    "y1=df.iloc[:,[2]].values\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "# le=LabelEncoder()\n",
    "# ohe=OneHotEncoder(categorical_features=[0])\n",
    "# X1[:,0]=le.fit_transform(X1[:,0])\n",
    "# X1=ohe.fit_transform(X1).toarray()\n",
    "\n",
    "ct = ColumnTransformer([(\"precip_type\", OneHotEncoder(), [0])], remainder = 'passthrough')\n",
    "X1 = ct.fit_transform(X1)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size = 0.6, random_state = 1)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "linear_model = LinearRegression()\n",
    "linear_model.fit(X1_train, y1_train)\n",
    "train1_predict=linear_model.predict(X1_train)\n",
    "test1_predict=linear_model.predict(X1_test)\n",
    "print('TRAINING Score=',linear_model.score(X1_train,y1_train))\n",
    "print('TESTING Score=',linear_model.score(X1_test,y1_test))\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "print('MAE on training Set=',mean_absolute_error(y1_train,train1_predict))\n",
    "print('MAE on testing Set=',mean_absolute_error(y1_test,test1_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  (b) Create an optimal regularised linear regression model and report the test performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING Score= 0.8940993719131628\n",
      "TESTING Score= 0.8942555558495825\n",
      "MAE on training Set= 2.550928664055756\n",
      "MAE on testing Set= 2.5572050413352208\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "model_ridge = Ridge(alpha = 0.5, normalize = True)\n",
    "model_ridge.fit(X1_train, y1_train)\n",
    "ytrain_predict = model_ridge.predict(X1_train)\n",
    "ytest_predict = model_ridge.predict(X1_test)\n",
    "\n",
    "print('TRAINING Score=',model_ridge.score(X1_train, y1_train))\n",
    "print('TESTING Score=',model_ridge.score(X1_test, y1_test))\n",
    "print('MAE on training Set=',mean_absolute_error(y1_train,ytrain_predict))\n",
    "print('MAE on testing Set=',mean_absolute_error(y1_test,ytest_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " (c) Explain the reason behind the performance variation, if any."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Performance Variation can be observed after using regularised linear regression model ridge. Mean absolute error of Ridge model is greater than Linear Regression model and score of Linear Regression model is greater than Ridge model.\n",
    "- The reason behind the performance variation is when we include regularization after linear regression, it shrinks the parameters, therefore, it is mostly used to prevent multicollinearity (which is not the case here). Also, it reduces the model complexity by coefficient shrinkage but decreases the score and hence MAE increases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CtcCZwIMOxwi"
   },
   "source": [
    "##**Part 2: Logistic Regression:**  **(9 marks)**\n",
    "\n",
    "\n",
    "1.  Can the same target (temperature, mentioned in Part-1) be used for logistic regression? Why? **(2 marks)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "knM4rfghOORu"
   },
   "source": [
    "Logistic Regression in a classification technique. Classification is process of classifying the categorical data \n",
    "but temperature (used as target variable in Part 1) is continous data. It cannot be divided into categories.\n",
    "Therefore, for predicting temperature we need regression technique as applied above in Part 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a5w0t5-To1nB"
   },
   "source": [
    "2.  Split the dataset as 70-30% for training and testing. Create a logistic regression model to predict the 'precip_type'. Report the prediction accuracy of your model whether the \"precip_type\" is \"rain\" or not (use decision threshold of 0.45). **(5 marks)**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vzRgiUq9wEHY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9827896046447332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hoangha/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "df['precip_type']=df['precip_type'].replace(['rain','snow'],['0','1'])\n",
    "X2=df.iloc[:,[2,3,4,5,6,7,8,9,11,12,13,14]].values\n",
    "y2=df.iloc[:,[1]].values\n",
    "y2=pd.DataFrame(data=y2)\n",
    "y2=y2.astype(int)\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size = 0.3, random_state = 1)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(random_state = 1)\n",
    "classifier.fit(X2_train, y2_train.values.ravel())\n",
    "THRESHOLD = 0.45\n",
    "pred_y=np.where(classifier.predict_proba(X2_test)[:,1] > THRESHOLD, 1, 0)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,precision_recall_fscore_support\n",
    "print(accuracy_score(y2_test,pred_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Yn7--XRkrIK9"
   },
   "source": [
    " 3.  Discuss the test performance using precision, recall and confusion matrix. **(2 marks)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7GpmkeRLOOkM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision-> 0.9907926184225992\n",
      "Recall-> 0.9897068607882274\n",
      "Confusion Matrix->\n",
      " [[25288   263]\n",
      " [  235  3150]]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y2_test, pred_y)\n",
    "precision,recall,fscore,support=precision_recall_fscore_support(y2_test,pred_y)\n",
    "print('Precision->',precision[0])\n",
    "print('Recall->',recall[0])\n",
    "print('Confusion Matrix->\\n',cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the model is 99.08% precise and has a recall value of 98.97%. If we consider the confusion matrix, we can see that the total of True positive is 25288 and True negative is 3150 while the false values are just 263 and 235 which shows that our model was able to predict the True values way more than than the False values. This shows the accuracy too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uJZCDkQcH_k6"
   },
   "source": [
    "##**Part 3: Objective function optimisation:**  **(6 marks)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7DrSojxhXpwL"
   },
   "source": [
    "Lets consider the line graphs shown below and answer the following questions [Hint: See weekly content 7.4-7.10],"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_eGL6Jz_KJdH"
   },
   "source": [
    "<html>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(a)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(b)</html>\n",
    "\n",
    "![image.png](data:image/png;base64,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)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iBRBSZiqKzLh"
   },
   "source": [
    "\n",
    "a.  Which of the above figures represents the convex objective function and why? (**1 marks**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure (a) represents convex function because in convex functions we have a condition: Local Minima = Global Minima. This is satisfied in figure (a) and hence its convex while (b) is not because it has different local minima and global minima."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b.  Which hyper-parameter can help to reach the convergence point and the impact of value selection? (**2 marks**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use Gradient Descent technique to reach the convergence point and the impact of value. It works by adjusting the weights to lower the cost of a function. We can find local minimas using this approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "c.  How can we find the global minima for the objective function shown in Figure-b? _[N.B. Conceptual description will be accepted.]_ (**3 marks**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure (b) shows a non convex function. We could have used Gradient descent if it would have been convex. But in this case, we can use Newton's method because it uses second derivative and can find global minima more accurately than Gradient descent (GD is best for local minima).\n",
    "\n",
    "To minimize a function L(W) we follow these steps (iteratively):\n",
    "W(t+1) = W(t) - H^(-1) * (derivative(L(W)))\n",
    "\n",
    "where H is Hessian Matrix and H(i,j) being the second derivative of L(W) with W(i) and W(j).\n",
    "\n",
    "This can be a faster method when the second derivative is known for the given function.\n",
    "\n",
    "Alternatively, we can also use Stochastic gradient descent in order to reach the convergence point."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "A3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
